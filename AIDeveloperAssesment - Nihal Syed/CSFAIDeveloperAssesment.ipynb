{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Processing Video Pipeline**\n",
        "\n",
        "To adapt a working ML model that can identify carrots in individual images for use in a live video inside a grocery store I would first make sure I have all the hardware and software requirements necessary. I would need a camera with sufficient resolution and frame rate to capture clear video footage, as well as a computer with a GPU capabale of handling the processing of video frames quickly enough for real time analysis. I would use OpenCV for frame extraction and handling the video stream. And I would have a database for logging the detected carrots. Firstly, I would set up the camera with open CV and load the pretrained model. Then, on every frame of the video I would first preprocess the frame to a format expected by the model. After that I would insert the frame to the model to make a predicition, I would then take the accuracy scorereturned by the model, we will assume we are using binary classification with a threshold, and if it is within the threshhold then I would log the carrot into the database. To enhance the accuracy I would use Non-maximum suppression techniques to reduce duplicate detections, as well as post processing steps to filter out false positives.\n"
      ],
      "metadata": {
        "id": "z3v934O11dYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample code to show how I would use a corrot detection model on a live video feed\n",
        "import cv2\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "#load the carrot model\n",
        "carrot_model = tf.keras.models.load_model('carrot_detection_model.h5')\n",
        "\n",
        "#function to log detected carrots\n",
        "def log_detection(frame):\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"detected_carrot_{timestamp}.jpg\"\n",
        "    cv2.imwrite(filename, frame)\n",
        "\n",
        "# Function to preprocess frames\n",
        "def preprocess_frame(frame):\n",
        "  width = 224\n",
        "  height = 224\n",
        "  resized_frame = cv2.resize(frame, (width, height))\n",
        "  normalized_frame = resized_frame / 255.0\n",
        "  return normalized_frame.reshape((1, height, width, 2))"
      ],
      "metadata": {
        "id": "XM8WQEBw3fwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Capture with default camera\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "if not cap.isOpened():\n",
        "  print(\"Error: Could not open video stream.\")\n",
        "  exit()\n",
        "\n",
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  #Preprocess the frame\n",
        "  preprocessed_frame = preprocess_frame(frame)\n",
        "\n",
        "  #predict with the carrot model\n",
        "  pred = carrot_model.predict(preprocessed_frame)\n",
        "  score = pred[0][0]\n",
        "\n",
        "  #if score is within a threshold then log the detection\n",
        "  if score > 0.7:\n",
        "    print(\"Carrot Detected\")\n",
        "    log_detection(frame)\n",
        "\n",
        "  cv2.imshow('Carrot Stream', frame)\n",
        "\n",
        "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "    break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "nuTrgriGCQ0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DEMO**\n",
        "Write a toy implementation of whatever machine learning concept you would like in order to demonstrate your skills:\n",
        "\n",
        "I will be using the MNIST dataset to train a CNN. The MNIST dataset consists of 70,000 images of handwritten digits (0-9) where each image is 28x28. We will load the dataset, preprocess it, and train a CNN model then evaluate its performance.\n",
        "\n",
        "The CNN Model consists of:\n",
        "- Input Layer: input shape of each image and the number of channels\n",
        "- Convolutional Layer 1: apply convolution operatioin on the input and extracts features like edges, textures, and shapes. Filters recognize different patterns in the images\n",
        "  *   32 Kernels\n",
        "  *   Kernel Size (3,3)\n",
        "  * Activation function ('relu')\n",
        "  * Input Shape (28, 28, 1)\n",
        "- Convolution layer 2\n",
        "  * 64 kernels\n",
        "  * Kernel Size (3,3)\n",
        "  * Activation Function ('relu')\n",
        "- Pooling layer: Reduces spatial dimensions of feature maps, keeping the most important features while reducing load\n",
        " * Pool Size (2,2)\n",
        "- Dropout Layer: Randomly set a fraction of the input units to 0 during training to prevent overfitting\n",
        " * Dropout Rate (0.25)\n",
        "- Flatten Layer: Conversts 2D feature maps into 1D vectors\n",
        "  * Layer flattens input to convert matrix into vector\n",
        "- Dense Layer: perform classification based on features extracted by the convolutional and pooling layers. The final dense layer uses softmax activation to output probabilites.\n",
        "  * 10 neurons, for each 10 classes of digits\n",
        "  * Activation Function (softmax)\n",
        "\n",
        "With the use of CNNs we can define and train a model that has 99% accuracy on the MNIST dataset. We could improve the model further by adding more spefic and fine tuned layers, or trying to combine multiple models to improve performance. We could also use different datasets so that the model is train on a wide variety of data.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WUInnBIY4gIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "LJTbQjgMEkRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape the data to include a single channel\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "\n",
        "# Normalize the pixel values to the range [0, 1]\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert the labels to categorical format\n",
        "y_train = to_categorical(Y_train, 10)\n",
        "y_test = to_categorical(Y_test, 10)"
      ],
      "metadata": {
        "id": "JPQsf0FdEnFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "D_pEaOW4E1i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "PUhzuWzME42f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=20, batch_size=128, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "E10nNRfNE75a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}